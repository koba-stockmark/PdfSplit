{
  "document": {
    "topic": {
      "abstract": "ビッグデータの利用が始まって間もない頃から、プライバシーをめぐる懸念によってデータ駆動型ソフトウェアの潜在力が制限されていた。\nたとえば2005年の「SoC083：プライバシー危機の蔓延」では、プライバシーへの脅威が急速に増えているようだと指摘されている。\n2013年の「SoC655：ビッグデータ、大きな懸念」では、ビッグデータ・システムの開発を望む企業が、データ規制や消費者のプライバシーへの期待など、さまざまな問題に直面している状況が紹介されている。\n2017年の「SoC933：スヌーピング技術」では、顧客サービスとプライバシーの侵害が、紙一重になりつつあると論じられた。\n2019年初頭の「SoC1059：（プ）レビュー2018/2019：データとプライバシー」では、2018年にScan™で採り上げられたプライバシー関連のトピックを総ざらいしている。\n2020年の「SoC1171：コロナウイルスと市民の自由」では、Covid-19（2019年型コロナウイルス感染症）パンデミック対策を目的としたデジタル・トラッキングの利用が、データ・プライバシーに真っ向から抵触する現状について解説している。\nしかし、データの大規模な収集・処理と、鉄壁の個人プライバシーとが互いに両立する未来が実現可能だとしたら、どうだろうか。\nこのような未来が訪れたら、プライバシーに関する規制や懸念事項に縛られずに、ビッグデータの潜在力がようやく解き放たれるかもしれない。\n一般的なデータ駆動型コンピューティングはもとより、データ駆動の人工知能が大きく進歩する可能性が高い。\n医療、教育、消費者サービスなどの分野でブレイクスルーが起こり得る。\nプライバシーの問題からデジタル変革の目標を穏便なものにしていた企業も、意欲的なデジタル戦略に踏み切れるようになるだろう。\n不確実性は存在するが、現時点で見られるさまざまな道しるべから、自動化によってプライバシーの問題が基本的に取り払われた遠い未来が、説得力をもって浮かび上がっている。\n自動プライバシー管理ツール、フェデレーテッド・マシン・ラーニングなどの新興のテクノロジーによって、企業が個人のプライバシーを保護しながら、急速に増大しつつあるデータを最大限に利用できるようになる可能性がある。\nヨーロッパの一般データ保護規則（GDPR）、カリフォルニア消費者プライバシー法など、プライバシー法制の順守を支援する半自動ソフトウェアは、さまざまなベンダーからすでに提供されている。\nこの種のソフトウェアが投資家の多大な関心を集めている。\nたとえば米国のBigID は、1億5,000万ドル近い資金を調達した。\n同社が提供するプラットフォームは、データ・アナリティクスと並行してコンプライアンス・ソフトウェアを使用することで、企業における個人データの識別とマッピングを支援する（これらのデータが、複数のオンプレミス・システムやクラウドベース・システムに分散されていても問題ない）。\nさらに、顧客や従業員からのデータ・アクセス要求の履行など、プライバシーに関連する機能が、このプラットフォームによって部分的に自動化される。\nまた、米国のSecuriti.aiは、設立後わずか2年強しか経っていないにも関わらず8,100万ドルの資金を調達している。\n同社もBigIDと同様、機械学習を利用して複数の場所に分散した個人データを管理し、プライバシー・コンプライアンスのさまざまな側面を部分的に自動化する。\n他にも事例がある。\n2019年5月に設立され現在までに4,000万ドルの資金を調達した米国のInCountryは、複数の司法権管轄区域に広がるデータ・ストレージの管理を通じて、企業におけるプライバシー・コンプライアンスを支援している。\nその他に注目すべきプロバイダーとしては、英国のPrivitar、米国のTrustArc、そして2020年中頃に競争相手のIntegris Softwareを買収した米国・英国のOneTrustがある。\n\nプライバシー管理ソリューションの出現によって、コンプライアンスにかなりの金額を投資できる企業と、そうでない企業との間で競争条件が公平化される可能性がある。\n米国のGoogle （Alphabet）では、GDPRの施行開始に先立って、GDPRコンプライアンスを確保する作業に延べ数百年に相当する人的時間が費やされたとみられる。\nプライバシー管理ツールを利用すると、法規制の順守に必要なコストが削減され、リスクが低下する。\nテクノロジー業界以外の企業でも、国際市場向けの新しいデータ・サービスの開発が促進される可能性がある。\n\nデータ・プライバシーの自動化を目的とするソフトウェアのもう1つの系統が、フェデレーテッド・ラーニング・システムによるAIである。\n機械学習AIは、データ・セット（通常、非常に大容量）に依存してインテリジェントな挙動を学習する。\nところが多くの場合、プライバシー法やプライバシーをめぐる懸念のため、機械学習に必要とされる十分なデータに開発者がアクセスすることができない。\nフェデレーテッド・ラーニング・システムは、AIトレーニング・タスクを個別のモジュールに分割し、これらのモジュールをローカル・デバイスに分散することにより、そのような懸念に対処するシステムである。\nたとえば、AIトレーニングに必要なデータが個人の携帯電話に含まれている場合、モジュール化した機械学習トレーニング・システムは、携帯電話それ自体に存在するデータを利用することができ、そのデータをクラウドにアップロードする必要はない（トレーニング済みのAIモジュールだけがアップロードされる）。\nフェデレーテッド機械学習ソフトウェアを開発している企業としては、米国のGoogle、IBM、Intel、Micosoftなどがある。\n\nプライバシーの自動化は、さらなる前進が期待できる。\n目立ったところでは、IBMが最近、完全準同型暗号（FHE）のフィールド試験を完了した。\nFHEは、コンピューターが暗号化データ\nを復号化せず、暗号化されたままの状態で演算や論理演算を実行することを可能にする暗号化技術である。\n基本的にFHEを使用すると、暗号化されていないデータに対して実行できる操作は何でも、暗号化された機密データに対して（少なくとも理論上は）実行できる。\nIBMによるこの前進は、将来への有望なステップになり得るが、FHEを使用するには、演算能力とメモリをかなり増強しなければならない。\nたとえば、FHEで暗号化された機械学習モデルは、非暗号化モデルと比べて、同じタスクを実行するために必要な演算能力は40～50倍、必要なメモリは10～20倍であることがIBMの試験で明らかになっている。\nこのようなパフォーマンス・トレードオフがあるため、金融サービス、医療、官庁などの業種への応用は、今のところ狭い範囲に限られそうだ。\nそれでも演算速度が向上しFHE 技法が進化するにつれ、トレードオフが軽減される可能性がある。\n\n自動プライバシー・ツールは今のところ限られており、ほとんどの場合、プライバシー関連のタスクを全面的に自動化するものではない。\nそれでも、企業がプライバシー・コンプライアンス・タスクを自動化できるようになり、個人データの処理によってプライバシーが危険にさらされることのない未来への道筋を指し示している。\nこのような未来の実現に向けて望みが持てそうになりつつあるが、それは少なくとも10 年は先の話であり、かなりの不確実性も存在する。\n技術的な課題はまだ顕著であり（たとえばFHEは依然として開発の初期段階である）、プライバシー保護ソフトウェアへの信頼も育てる必要がある。\n喜ばしいことに、このような未来に至る道筋には、さまざまな可能性が存在する。\nたとえば、すでに出回っている市販のツールを利用して、プライバシー・コンプライアンスを能率化することはすぐにでも可能である。\n",
      "related_topic": []
    }
  },
  "date": "2020年12月",
  "id": "SoC1198 ",
  "title_english": "Automating Privacy in Data Use ",
  "author": "By Rob Edmonds（Send us feedback）",
  "title": "データ利用におけるプライバシーの自動化",
  "summary": "プライバシー管理ツールを利用すると、法規制の順守に必要なコストが削減され、リスクが低下する。",
  "soc_link": [
    "SoC1171  コロナウイルスと市民の自由 ",
    "SoC1059  （プ）レビュー2018/2019：データとプライバシー  P0843  プライバシーとセキュリティ：難しいバランス ",
    "SoC843 "
  ],
  "partners_link": [
    "P1273  監視技術はもろ刃の剣 ",
    "P0661  2014 年における『1984 年』 "
  ]
}